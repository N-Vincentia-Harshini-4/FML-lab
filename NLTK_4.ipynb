{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiqeUpKOuTisZY2oTgXbwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N-Vincentia-Harshini-4/FML-lab/blob/main/NLTK_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oIQ-js2V11s",
        "outputId": "81937932-36ec-4cf3-cd64-88070106d0e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "eset=\"\"\" We are learning natural language processing as part of fundamentals of machine learning in our second year \"\"\"\n",
        "stop_words=set(stopwords.words('english'))\n",
        "word_tokens=word_tokenize(eset)\n",
        "fil_sen=[w for w in word_tokens if  not w.lower() in stop_words]\n",
        "fil_sen=[]\n",
        "for w in word_tokens:\n",
        "  if w not in stop_words:\n",
        "    fil_sen.append(w)\n",
        "print(word_tokens)\n",
        "print(fil_sen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rommQ0JLQ2gT",
        "outputId": "19b39514-6a7c-47f8-e562-c2921455f83f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'are', 'learning', 'natural', 'language', 'processing', 'as', 'part', 'of', 'fundamentals', 'of', 'machine', 'learning', 'in', 'our', 'second', 'year']\n",
            "['We', 'learning', 'natural', 'language', 'processing', 'part', 'fundamentals', 'machine', 'learning', 'second', 'year']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='There was once a hare who was friends with a tortoise. One day, he challenged the tortoise to a race. Seeing how slow the tortoise was going, the hare thought he’d win this easily. So, he took a nap while the tortoise kept on going. When the hare woke, he saw that the tortoise was already at the finish line. Much to his chagrin, the tortoise won the race while he was busy sleeping.'\n",
        "tokens=text.split()\n",
        "print(tokens)\n",
        "print(\"no.of tokens:\",len(tokens))\n",
        "sen=text.split('.')\n",
        "print(sen)\n",
        "print(\"No.of sentences :\",len(sen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11NOV3gbVYhU",
        "outputId": "c1177eb0-77f7-4e42-ce9c-6db9acdc362b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There', 'was', 'once', 'a', 'hare', 'who', 'was', 'friends', 'with', 'a', 'tortoise.', 'One', 'day,', 'he', 'challenged', 'the', 'tortoise', 'to', 'a', 'race.', 'Seeing', 'how', 'slow', 'the', 'tortoise', 'was', 'going,', 'the', 'hare', 'thought', 'he’d', 'win', 'this', 'easily.', 'So,', 'he', 'took', 'a', 'nap', 'while', 'the', 'tortoise', 'kept', 'on', 'going.', 'When', 'the', 'hare', 'woke,', 'he', 'saw', 'that', 'the', 'tortoise', 'was', 'already', 'at', 'the', 'finish', 'line.', 'Much', 'to', 'his', 'chagrin,', 'the', 'tortoise', 'won', 'the', 'race', 'while', 'he', 'was', 'busy', 'sleeping.']\n",
            "no.of tokens: 74\n",
            "['There was once a hare who was friends with a tortoise', ' One day, he challenged the tortoise to a race', ' Seeing how slow the tortoise was going, the hare thought he’d win this easily', ' So, he took a nap while the tortoise kept on going', ' When the hare woke, he saw that the tortoise was already at the finish line', ' Much to his chagrin, the tortoise won the race while he was busy sleeping', '']\n",
            "No.of sentences : 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "tokens=re.findall(\"[\\w']+\",text)\n",
        "print(tokens)\n",
        "print(\"No.of tokens:\",len(tokens))\n",
        "sen=re.compile('[.?!]').split(text)\n",
        "print(sen)\n",
        "print(\"No.of sentences:\",len(sen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoxsBOOWQ2n7",
        "outputId": "96a78561-5758-4cf4-98e2-4199861aff20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There', 'was', 'once', 'a', 'hare', 'who', 'was', 'friends', 'with', 'a', 'tortoise', 'One', 'day', 'he', 'challenged', 'the', 'tortoise', 'to', 'a', 'race', 'Seeing', 'how', 'slow', 'the', 'tortoise', 'was', 'going', 'the', 'hare', 'thought', 'he', 'd', 'win', 'this', 'easily', 'So', 'he', 'took', 'a', 'nap', 'while', 'the', 'tortoise', 'kept', 'on', 'going', 'When', 'the', 'hare', 'woke', 'he', 'saw', 'that', 'the', 'tortoise', 'was', 'already', 'at', 'the', 'finish', 'line', 'Much', 'to', 'his', 'chagrin', 'the', 'tortoise', 'won', 'the', 'race', 'while', 'he', 'was', 'busy', 'sleeping']\n",
            "No.of tokens: 75\n",
            "['There was once a hare who was friends with a tortoise', ' One day, he challenged the tortoise to a race', ' Seeing how slow the tortoise was going, the hare thought he’d win this easily', ' So, he took a nap while the tortoise kept on going', ' When the hare woke, he saw that the tortoise was already at the finish line', ' Much to his chagrin, the tortoise won the race while he was busy sleeping', '']\n",
            "No.of sentences: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens=word_tokenize(text)\n",
        "print(tokens)\n",
        "print(\"No.of tokens:\",len(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgjAS7GZQ2vK",
        "outputId": "132e9da3-d925-4f37-9e8f-f3837dec2a82"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There', 'was', 'once', 'a', 'hare', 'who', 'was', 'friends', 'with', 'a', 'tortoise', '.', 'One', 'day', ',', 'he', 'challenged', 'the', 'tortoise', 'to', 'a', 'race', '.', 'Seeing', 'how', 'slow', 'the', 'tortoise', 'was', 'going', ',', 'the', 'hare', 'thought', 'he', '’', 'd', 'win', 'this', 'easily', '.', 'So', ',', 'he', 'took', 'a', 'nap', 'while', 'the', 'tortoise', 'kept', 'on', 'going', '.', 'When', 'the', 'hare', 'woke', ',', 'he', 'saw', 'that', 'the', 'tortoise', 'was', 'already', 'at', 'the', 'finish', 'line', '.', 'Much', 'to', 'his', 'chagrin', ',', 'the', 'tortoise', 'won', 'the', 'race', 'while', 'he', 'was', 'busy', 'sleeping', '.']\n",
            "No.of tokens: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sen=sent_tokenize(text)\n",
        "print(sen)\n",
        "print(\"No.of sentencces:\",len(sen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4Y4W9gjQ21S",
        "outputId": "ae8c412f-4512-438a-e92e-737267f1fb1b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There was once a hare who was friends with a tortoise.', 'One day, he challenged the tortoise to a race.', 'Seeing how slow the tortoise was going, the hare thought he’d win this easily.', 'So, he took a nap while the tortoise kept on going.', 'When the hare woke, he saw that the tortoise was already at the finish line.', 'Much to his chagrin, the tortoise won the race while he was busy sleeping.']\n",
            "No.of sentencces: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter=PorterStemmer()\n",
        "sen=\"There are a couple of moral lessons we can learn from this story. The hare teaches that overconfidence can sometimes ruin you. While the tortoise teaches us about the power of perseverance. Even if all the odds are stacked against you, never give up. Sometimes, life is not about who’s the fastest or the strongest; it’s about who is the most consistent.\"\n"
      ],
      "metadata": {
        "id": "cQpFwTbzQ236"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "def stemsen(sen):\n",
        "  token_words=word_tokenize(sen)\n",
        "  print(token_words)\n",
        "  stem_sen=[]\n",
        "  for word in token_words:\n",
        "    stem_sen.append(porter.stem(word))\n",
        "    stem_sen.append(\" \")\n",
        "  return \"\".join(stem_sen)\n",
        "x=stemsen(sen)\n",
        "print(\"Sentence after stemming:\",x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd27uZvFa8ow",
        "outputId": "e7f0ea37-1738-4845-f7d8-c4620a011a28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There', 'are', 'a', 'couple', 'of', 'moral', 'lessons', 'we', 'can', 'learn', 'from', 'this', 'story', '.', 'The', 'hare', 'teaches', 'that', 'overconfidence', 'can', 'sometimes', 'ruin', 'you', '.', 'While', 'the', 'tortoise', 'teaches', 'us', 'about', 'the', 'power', 'of', 'perseverance', '.', 'Even', 'if', 'all', 'the', 'odds', 'are', 'stacked', 'against', 'you', ',', 'never', 'give', 'up', '.', 'Sometimes', ',', 'life', 'is', 'not', 'about', 'who', '’', 's', 'the', 'fastest', 'or', 'the', 'strongest', ';', 'it', '’', 's', 'about', 'who', 'is', 'the', 'most', 'consistent', '.']\n",
            "Sentence after stemming: there are a coupl of moral lesson we can learn from thi stori . the hare teach that overconfid can sometim ruin you . while the tortois teach us about the power of persever . even if all the odd are stack against you , never give up . sometim , life is not about who ’ s the fastest or the strongest ; it ’ s about who is the most consist . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i9O3nVRdWJI",
        "outputId": "535b4652-c3ae-4c96-f756-f42521007a31"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lem=WordNetLemmatizer()\n",
        "print(wordnet_lem.lemmatize(\"trouble\"))\n",
        "print(wordnet_lem.lemmatize(\"cats\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNH07Bvxa8hp",
        "outputId": "a85035d4-0edc-4b3b-c762-7a770574ed34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trouble\n",
            "cat\n"
          ]
        }
      ]
    }
  ]
}